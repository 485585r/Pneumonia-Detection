{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "DATASET USED:  https://data.mendeley.com/datasets/rscbjbr9sj/3"
      ],
      "metadata": {
        "id": "9imi0QBTKmde"
      },
      "id": "9imi0QBTKmde"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "81af4b3b",
      "metadata": {
        "id": "81af4b3b",
        "outputId": "69fb2900-a600-41b2-ca67-dbeb52a2683f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "No GPU detected.\n"
          ]
        }
      ],
      "source": [
        "# Importing libraries\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import PIL\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.data import AUTOTUNE\n",
        "\n",
        "train_dir = 'C:/chest_xray/train'\n",
        "\n",
        "\n",
        "#check for GPU availability (if available, it uses CUDA)\n",
        "\n",
        "if tf.test.gpu_device_name():\n",
        "    print('GPU is available.')\n",
        "else:\n",
        "    print('No GPU detected.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8b94f762",
      "metadata": {
        "id": "8b94f762",
        "outputId": "57e49c4c-37bb-459a-e430-b920d4e8e5ed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 5232 files belonging to 2 classes.\n",
            "Using 4186 files for training.\n"
          ]
        }
      ],
      "source": [
        "#define the training data\n",
        "\n",
        "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "    train_dir,\n",
        "    subset=\"training\",\n",
        "    validation_split=0.2, #percentage of data used for training\n",
        "    seed=123,\n",
        "    image_size=(180, 180),\n",
        "    batch_size=32,#how many images used per epoch before parameters are updated\n",
        "    color_mode=\"grayscale\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8eb30a94",
      "metadata": {
        "id": "8eb30a94"
      },
      "outputs": [],
      "source": [
        "test_dir ="
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f515f481",
      "metadata": {
        "id": "f515f481",
        "outputId": "df2c78f2-7836-4789-95ef-34e516542d56"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 5232 files belonging to 2 classes.\n",
            "Using 1046 files for validation.\n"
          ]
        }
      ],
      "source": [
        "# Testing or Validation split\n",
        "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "    test_dir,\n",
        "    subset=\"validation\",\n",
        "    validation_split=0.2,\n",
        "    seed=123,\n",
        "    image_size=(180,180),\n",
        "    batch_size=32,\n",
        "    color_mode=\"grayscale\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e4a1a93b",
      "metadata": {
        "id": "e4a1a93b",
        "outputId": "5997cefa-3012-4c33-857c-50a7131b6e90"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['NORMAL', 'PNEUMONIA']\n"
          ]
        }
      ],
      "source": [
        "class_names = train_ds.class_names\n",
        "print(class_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "36b208f1",
      "metadata": {
        "id": "36b208f1"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import regularizers\n",
        "\n",
        "num_classes = len(class_names)\n",
        "\n",
        "model = Sequential([\n",
        "  layers.Rescaling(1./255, input_shape=(180, 180, 1)),\n",
        "  layers.Conv2D(16, 3, strides=2, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Flatten(),\n",
        "  layers.Dense(128, activation='relu', activity_regularizer=regularizers.L2(0.01)),\n",
        "  layers.BatchNormalization(),\n",
        "  layers.Dense(1, activation='sigmoid', activity_regularizer=regularizers.L2(0.01))\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fb317d7b",
      "metadata": {
        "id": "fb317d7b",
        "outputId": "4d5f7da1-35f8-43e2-e2a6-a616f881ce59"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " rescaling (Rescaling)       (None, 180, 180, 1)       0         \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 90, 90, 16)        160       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 45, 45, 16)        0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 32400)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               4147328   \n",
            "                                                                 \n",
            " batch_normalization (Batch  (None, 128)               512       \n",
            " Normalization)                                                  \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4148129 (15.82 MB)\n",
            "Trainable params: 4147873 (15.82 MB)\n",
            "Non-trainable params: 256 (1.00 KB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.compile(\n",
        "    optimizer=keras.optimizers.Adam(1e-5),\n",
        "    loss=\"binary_crossentropy\",\n",
        "    metrics=[\"accuracy\"],\n",
        ")\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f2377c3d",
      "metadata": {
        "id": "f2377c3d",
        "outputId": "fdd50385-3d53-4956-afab-0ec4bdaeb724"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/7\n",
            "131/131 [==============================] - 43s 317ms/step - loss: 0.1772 - accuracy: 0.9577 - val_loss: 0.2928 - val_accuracy: 0.9187\n",
            "Epoch 2/7\n",
            "131/131 [==============================] - 45s 333ms/step - loss: 0.1663 - accuracy: 0.9611 - val_loss: 0.4516 - val_accuracy: 0.8480\n",
            "Epoch 3/7\n",
            "131/131 [==============================] - 49s 362ms/step - loss: 0.1534 - accuracy: 0.9658 - val_loss: 0.1777 - val_accuracy: 0.9618\n",
            "Epoch 4/7\n",
            "131/131 [==============================] - 53s 390ms/step - loss: 0.1406 - accuracy: 0.9730 - val_loss: 0.2181 - val_accuracy: 0.9426\n",
            "Epoch 5/7\n",
            "107/131 [=======================>......] - ETA: 8s - loss: 0.1321 - accuracy: 0.9766"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "KeyboardInterrupt\n",
            "\n"
          ]
        }
      ],
      "source": [
        "epochs=7\n",
        "model.fit(\n",
        "train_ds,\n",
        "validation_data=val_ds,\n",
        "epochs=epochs\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b7ad3982",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "856ed93deccc428897937e61c3cc03f8",
            "aa46d00e18e74fa98d4cf7d7f7e10f26",
            "78507f9900df4be09e57fcd871916691",
            "175aa03c07ee42de998031a5101669aa",
            "ded912cd550945688959a5b483f25dd0"
          ]
        },
        "id": "b7ad3982",
        "outputId": "208bec6c-9a94-44ee-f25c-84d520aa9f51"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "856ed93deccc428897937e61c3cc03f8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Label(value='Upload an image:')"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "aa46d00e18e74fa98d4cf7d7f7e10f26",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "FileUpload(value=(), accept='.jpg,.png', description='Upload')"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "78507f9900df4be09e57fcd871916691",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Output()"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "175aa03c07ee42de998031a5101669aa",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Label(value='Prediction:')"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ded912cd550945688959a5b483f25dd0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Output()"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "This image is 15.31% normal and 84.69% pneumonia.\n",
            "This image is 5.12% normal and 94.88% pneumonia.\n"
          ]
        }
      ],
      "source": [
        "import ipywidgets as widgets\n",
        "from IPython.display import display\n",
        "from IPython.display import clear_output\n",
        "from PIL import Image\n",
        "import io\n",
        "\n",
        "\n",
        "upload_button = widgets.FileUpload(accept='.jpg,.png', multiple=False)\n",
        "image_output = widgets.Output()\n",
        "prediction_output = widgets.Output()\n",
        "\n",
        "# Define prediction function\n",
        "def predict_image(change):\n",
        "    image_output.clear_output()\n",
        "    prediction_output.clear_output()\n",
        "\n",
        "    if len(upload_button.value) == 0:\n",
        "        with prediction_output:\n",
        "            print(\"Please upload an image.\")\n",
        "        return\n",
        "\n",
        "    uploaded_image = upload_button.value[0]\n",
        "    image_content = uploaded_image['content']\n",
        "    image = Image.open(io.BytesIO(image_content)).convert('L')\n",
        "    image = image.resize((180, 180))\n",
        "    img_array = tf.keras.utils.img_to_array(image)\n",
        "    img_array = tf.expand_dims(img_array, 0)\n",
        "\n",
        "    with image_output:\n",
        "        display(image)\n",
        "\n",
        "    with prediction_output:\n",
        "        predictions = model.predict(img_array)\n",
        "        score = float(predictions[0])\n",
        "\n",
        "    print(f\"This image is {100 * (1-score):.2f}% normal and {100 * score:.2f}% pneumonia.\")\n",
        "\n",
        "# Attach function to button click event\n",
        "upload_button.observe(predict_image, names='value')\n",
        "\n",
        "# Display widgets\n",
        "display(widgets.Label(\"Upload an image:\"))\n",
        "display(upload_button)\n",
        "display(image_output)\n",
        "display(widgets.Label(\"Prediction:\"))\n",
        "display(prediction_output)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}